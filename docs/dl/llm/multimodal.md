
### 多模态


| 名词   | 概念                                                                     |
| ------ | ------------------------------------------------------------------------ |
| 分词器（Tokenizer）|  将Prompt拆分为离散的Token |
| embedding |     将Token转换为高维向量                 |
| 编码器  |       提取深层语义特征               |
| 解码器  |       逐步预测下一个Token（如使用 Top-k采样 或 束搜索 或 贪心搜索）               |

贪心搜索：选择概率最高的Token（速度快但可能陷入局部最优）；
束搜索：保留多个候选序列（平衡质量与速度）；
采样方法（如Top-k、核采样）：引入随机性提升多样性


模型优化:
- 模型压缩：
  - 参数剪枝：通过去除神经网络中不重要的连接或神经元，减少模型的参数量，从而在不影响模型性能的情况下，提高模型的计算效率和响应速度。
  - 量化：将模型中的高精度参数（如32位浮点数）转换为低精度参数（如8位或16位整数），降低模型的存储需求和计算复杂度，加速模型的推理过程。
- 知识蒸馏：将大型复杂模型（教师模型）的知识迁移到小型简单模型（学生模型）中。学生模型在学习过程中模仿教师模型的输出或中间表示，从而在保持较高性能的同时，具有更快的推理速度，适合在资源受限的环境下快速响应用户请求。

Embedding 是多模态的基石

映射表的大小取决于词汇表的大小和 embedding 向量的维度


通过V × D 的矩阵，用来把 token id → 高维向量


- 每种模态（图像/音频/视频/文本）都需要专门的“编码器”把原始信号映射到一个或一系列 d 维的向量 Token。
- 这些向量不是“随便一组随机数”，而是通过预训练（自监督、对比、分类、生成等）得到的，能够保留该模态在语义/时序/空间上的关键信息。

对齐与融合是多模态理解的核心

- 对齐（Alignment）：让不同模态的 Embedding 落到同一个可比的“共享空间”里，常用 Contrastive Loss 让相同语义的多模态对更相似。
- 融合（Fusion）：文本的 embedding 与图像的 embedding 拼接, 通过 Cross-Attention、拼接、联合 Transformer 等方式，让信息互相交融，捕捉更丰富的多模态关联。

图像/音频/视频三者差异与融合思路

- 图像：静态二维信息，常用 CNN/ViT → Patch/全局 Vector；
- 音频：时序一维波形 → Mel-Spectrogram → 声学 Encoder → 时序 Token 序列或全局 Vector；
- 视频：既有时序又有空间，或者“逐帧 + 时序建模”，或直接用 3D Conv/Tubelet → 获得时空特征。

融合策略可以根据任务需求决定：是“图像+文本”对齐做检索，还是“视频+音频+文本”做问答、多模态对话，都用同一个思路：先各自嵌入 → 再对齐 / 融合 → 最终下游 Head 推理或生成。

