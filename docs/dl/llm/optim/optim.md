## 模型压缩


### 模型量化

量化 (INT8/GPTQ/AWQ)、

将模型的参数（如权重和激活值）从高精度转换为低精度的过程

llama.cpp
转gguf

### 参数剪枝：

通过去除神经网络中不重要的连接或神经元，减少模型的参数量，从而在不影响模型性能的情况下，提高模型的计算效率和响应速度。

剪枝、推理加速 (vllm/TensorRT-LLM)

### 模型性能优化

问答 -> 用户反馈
SFT

包 peft

合并模型

- 参数调优
- 性能评估

### 知识蒸馏：

将大型复杂模型（教师模型）的知识迁移到小型简单模型（学生模型）中。

学生模型在学习过程中模仿教师模型的输出或中间表示，从而在保持较高性能的同时，具有更快的推理速度，适合在资源受限的环境下快速响应用户请求。



### MoE（混合专家模型）




