## app

- notebooklm
- mita ai


## 原理


```mermaid
flowchart TD
    A[输入原始文本] --> B

    subgraph B[第一阶段：深度理解与编码]
        B1[分词与向量化<br>将文本转化为数学向量]
        B2[多层Transformer编码<br>通过自注意力机制捕捉上下文， 计算任意两个token之间的注意力权重]
    end

    B --> C[生成“文本的数学地图”<br>（包含所有语义与潜在关系的深度表示）]

    C --> D

    subgraph D[第二阶段：分析与结构化]
        direction LR
        D1[实体与概念识别<br>定位关键“节点”]
        D2[关系与逻辑分析<br>使用注意力权重与逻辑推理连接节点]
        D3[重要性评估与筛选<br>判断节点的核心程度]
    end

    D --> E

    subgraph E[第三阶段：结构化输出]
        E1[生成层级大纲<br>（如Markdown）]
        E2[生成关系图谱代码<br>（如Mermaid）]
    end
```


多层Transformer



### 推理 Chain-of-Thought + Tree-of-Thought

思维链推理(chain-of-thought, CoT)是大语言模型处理复杂推理任务的重要能力。

CoT通过将问题分解为多个子问题，并逐步解决每个子问题，最终汇总得出完整答案 。

这种方式不仅提高了模型的准确性，还增强了推理过程的可解释性。






2024年以后最好的思维导图效果，全部来自隐式的ToT（思想树）
模型在生成前，会在内部先进行几步自问自答（你看不到，但CoT提示词能逼出来）：
```
这篇文章的终极目标/核心命题是什么？（找中心节点）
为了论证这个命题，作者用了哪几大论据/模块？（找一级分支）
每个模块内部的逻辑链条是什么？（找二级、三级）
有没有并列、因果、对立、递进、例证关系？
有没有隐藏的潜在假设、前置条件、风险点？
```
Claude 3.5 Sonnet/Opus 在这一步是目前最强的，它会自动构建一个隐式的思想树，然后再把树结构输出成思维导图。