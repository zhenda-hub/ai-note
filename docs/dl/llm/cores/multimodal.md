
### 多模态


| 名词   | 概念                                                                     |
| ------ | ------------------------------------------------------------------------ |
| 分词器（Tokenizer）|  将Prompt拆分为离散的Token |
| embedding |     将Token转换为高维向量                 |
| 编码器  |       提取深层语义特征               |
| 解码器  |       逐步预测下一个Token（如使用 Top-k采样 或 束搜索 或 贪心搜索）               |

- 贪心搜索：选择概率最高的Token（速度快但可能陷入局部最优）；
- 束搜索：保留多个候选序列（平衡质量与速度）；
- 采样方法（如Top-k、核采样）：引入随机性提升多样性


### Embedding 是多模态的基石

映射表的大小取决于词汇表的大小和 embedding 向量的维度


通过V × D 的矩阵，用来把 token id → 高维向量


- 每种模态（图像/音频/视频/文本）都需要专门的“编码器”把原始信号映射到一个或一系列 d 维的向量 Token。
- 这些向量不是“随便一组随机数”，而是通过预训练（自监督、对比、分类、生成等）得到的，能够保留该模态在语义/时序/空间上的关键信息。

对齐与融合是多模态理解的核心

- 对齐（Alignment）：让不同模态的 Embedding 落到同一个可比的“共享空间”里，常用 Contrastive Loss 让相同语义的多模态对更相似。
- 融合（Fusion）：文本的 embedding 与图像的 embedding 拼接, 通过 Cross-Attention、拼接、联合 Transformer 等方式，让信息互相交融，捕捉更丰富的多模态关联。

图像/音频/视频三者差异与融合思路

- 图像：静态二维信息，常用 CNN/ViT → Patch/全局 Vector；
- 音频：时序一维波形 → Mel-Spectrogram → 声学 Encoder → 时序 Token 序列或全局 Vector；
- 视频：既有时序又有空间，或者“逐帧 + 时序建模”，或直接用 3D Conv/Tubelet → 获得时空特征。

融合策略可以根据任务需求决定：是“图像+文本”对齐做检索，还是“视频+音频+文本”做问答、多模态对话，都用同一个思路：先各自嵌入 → 再对齐 / 融合 → 最终下游 Head 推理或生成。

