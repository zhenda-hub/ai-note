基于 Transformer 架构，通过在海量数据上的“预训练”和“微调”，学习如何预测序列中的下一个概率最大的词。

## 核心架构：Transformer
Transformer 是几乎所有现代 LLM 的“发动机”。它在 2017 年由 Google 提出，彻底改变了 AI 处理语言的方式。

并行处理： 传统的模型（如 RNN）必须按顺序一个词一个词地处理，而 Transformer 可以同时处理整个句子。这使得它能在大规模并行硬件（GPU）上高效训练。

位置编码（Positional Encoding）： 由于 Transformer 同时读入所有词，它需要一套数学标签来标记单词在句子中的顺序，从而理解“狗咬人”和“人咬狗”的区别。

### 魔法核心：自注意力机制 (Self-Attention)

模型通过计算输入序列中每个词（或token）与其他所有词的相关性，来动态加权它们的重要性。

其数学表达通常通过查询（Query）、键（Key）和值（Value）来实现，公式如下：

$$Attention(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

注意力机制会给文本中 “重要的词” 分配更高的权重。识别文本中的关键实体，比如技术名称、领域名称、产品名称等。


### 多头注意力（Multi-Head Attention）：
将自注意力扩展到多个“头”，每个头独立计算注意力，捕捉不同方面的关系（如语法、语义），然后拼接结果。
名词与名词的关联关系
这增强了模型的表达能力。



Transformer 模型通常有几十层。
底层： 识别语法、单词含义。
中层： 理解句子间的逻辑（转折、因果）。
高层： 抽取抽象概念和全局意图。


### 位置编码（Positional Encoding）：
由于自注意力不考虑顺序，模型通过添加正弦/余弦函数生成的固定位置向量，来注入序列位置信息。

解决自注意力机制的无序性问题，确保模型理解词语顺序

### 前馈网络（Feed-Forward Network）和层归一化（Layer Normalization）：
每个Transformer块包括自注意力子层和全连接前馈子层，中间添加残差连接（Residual Connection）和归一化，以稳定训练深层网络。

### 整体架构：
原始Transformer包括编码器（Encoder）和解码器（Decoder）栈，每个栈由多个相同层组成。
现代LLM多采用“解码器-only”变体（如GPT），专注于自回归生成：通过“下一个token预测”（Next-Token Prediction）任务，在海量无标签文本上预训练，学习语言模式。

## 学习范式

LLM 的能力源于大规模预训练与针对性微调的两阶段学习范式。

1. 预训练阶段：构建通用语言能力
数据规模：万亿级 token，涵盖网页、书籍、论文、对话等各类文本
核心任务：
自回归语言建模（GPT 类）：预测下一个 token 的概率，最大化序列生成的似然性
掩码语言建模（BERT 类）：随机掩盖部分 token，让模型预测被掩盖内容
学习目标：掌握语法、语义、逻辑推理和世界知识，形成通用语言表示

2. 微调阶段：适配特定任务
监督微调 (SFT)：使用标注数据微调模型，使其输出符合人类期望
对齐优化：
RLHF（基于人类反馈的强化学习）：通过人类偏好训练奖励模型，再用 PPO 算法优化模型输出
DPO（直接偏好优化）：简化 RLHF 流程，直接通过偏好数据优化模型
参数高效微调 (PEFT)：如 LoRA，冻结预训练权重，仅训练少量新增参数，降低成本


## 生成机制

生成机制：自回归解码 —— 让模型 "开口说话"
LLM 的文本生成遵循严格的自回归流程，逐 token 生成，确保连贯性。

完整生成流程
plaintext
输入(Prompt) → Tokenization(分词) → Embedding(向量化) → Transformer解码层 → 
语言模型头(LM Head) → Softmax(概率分布) → 采样(选下一个token) → 
添加到输入序列 → 重复直到生成结束符(EOS)

关键技术点
Tokenization：将文本拆分为子词单元（如 GPT 的 Byte-Pair Encoding），平衡词汇量与语义完整性
KV 缓存：缓存已生成 token 的键值对，避免重复计算，提升推理速度
采样策略：
贪心搜索：每次选概率最高的 token，生成最保守但可能重复的文本
束搜索：保留前 N 个最佳候选，平衡多样性与准确性
温度采样：控制输出随机性（温度 > 1 更随机，<1 更确定）


